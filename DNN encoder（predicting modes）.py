# -*- coding: utf-8 -*-
"""
Created on  Aug 8 10:13:40 2025

@author: Lpc
"""
import os
import numpy as np
import joblib
import tensorflow as tf
from tensorflow.keras.models import load_model
from sklearn.preprocessing import RobustScaler
from tensorflow.keras.layers import Layer, Dense, BatchNormalization, Reshape
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
import tensorflow as tf


class PhysicsResBlock(Layer):
    def __init__(self, units, **kwargs):
        super().__init__(**kwargs)
        self.units = units
        self.dense1 = Dense(units, activation=tf.nn.leaky_relu, kernel_regularizer=l2(0.001))
        self.bn1 = BatchNormalization()
        self.dense2 = Dense(units, activation=tf.nn.leaky_relu, kernel_regularizer=l2(0.001))
        self.bn2 = BatchNormalization()
        self.projection = Dense(units) if units else None

    def call(self, inputs):
        residual = inputs
        x = self.dense1(inputs)
        x = self.bn1(x)
        x = self.dense2(x)
        x = self.bn2(x)
        if self.projection:
            residual = self.projection(residual)
        x += residual
        return tf.nn.leaky_relu(x)

    def get_config(self):
        config = super().get_config()
        config.update({'units': self.units})
        return config


class PhysicsInformedNN(Model):
    def __init__(self, input_dim, output_dim, n_x, n_y, pca_layer, name="PhysicsInformedNN", **kwargs):
        super().__init__(name=name, **kwargs)
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.n_x = n_x
        self.n_y = n_y
        self.pca_rebuild = pca_layer

        self.input_norm = BatchNormalization()
        self.res_blocks = [
            PhysicsResBlock(256),
            PhysicsResBlock(256),
            PhysicsResBlock(256),
            PhysicsResBlock(256),
            PhysicsResBlock(256),
            PhysicsResBlock(256)
        ]
        self.output_layer = Dense(output_dim)

    def build(self, input_shape):
        self.inflow_coeff = self.add_weight(
            name='inflow_coeff',
            shape=(),
            initializer=tf.constant_initializer(1.0),
            constraint=lambda x: tf.clip_by_value(x, 0.7, 1.3),
            trainable=True
        )
        self.outflow_coeff = self.add_weight(
            name='outflow_coeff',
            shape=(),
            initializer=tf.constant_initializer(1.0),
            constraint=lambda x: tf.clip_by_value(x, 0.7, 1.3),
            trainable=True
        )
        super().build(input_shape)

    def get_config(self):
        config = super().get_config()
        config.update({
            'input_dim': self.input_dim,
            'output_dim': self.output_dim,
            'n_x': self.n_x,
            'n_y': self.n_y,
            'pca_layer': tf.keras.layers.serialize(self.pca_rebuild)
        })
        return config

    @classmethod
    def from_config(cls, config):
        try:
            if 'name' not in config:
                config['name'] = "PhysicsInformedNN"

            pca_layer_config = config.pop('pca_layer')
            pca_layer = tf.keras.layers.deserialize(
                pca_layer_config,
                custom_objects={'PCARebuildLayer': PCARebuildLayer}
            )
            return cls(pca_layer=pca_layer, **config)
        except KeyError as e:
            raise ValueError(f"ç¼ºå¤±å…³é”®é…ç½®é¡¹: {str(e)}") from e

    def build_shape_functions(self, batch_size):
        x_norm = tf.linspace(0.0, 1.0, self.n_x)
        x_norm = tf.reshape(x_norm, [1, self.n_x, 1])
        x_norm = tf.tile(x_norm, [batch_size, 1, self.n_y])

        phi_in = 1 - x_norm
        phi_out = x_norm
        return phi_in, phi_out

    def apply_boundary_constraints(self, raw_output, batch_size):
        raw_real = raw_output[..., 0]
        raw_imag = raw_output[..., 1]

        phi_in, phi_out = self.build_shape_functions(batch_size)

        phi_in_condition = phi_in > 0.99
        phi_out_condition = phi_out > 0.99

        constrained_real = tf.where(
            phi_in_condition,
            self.inflow_coeff * tf.ones_like(raw_real),
            tf.where(
                phi_out_condition,
                self.outflow_coeff * tf.ones_like(raw_real),
                raw_real
            )
        )

        constrained_imag = tf.where(
            phi_in_condition,
            self.inflow_coeff * tf.ones_like(raw_imag),
            tf.where(
                phi_out_condition,
                self.outflow_coeff * tf.ones_like(raw_imag),
                raw_imag
            )
        )

        return tf.stack([constrained_real, constrained_imag], axis=-1)

    def call(self, inputs):
        batch_size = tf.shape(inputs)[0]
        x = self.input_norm(inputs)

        for block in self.res_blocks:
            x = block(x)

        raw_features = self.output_layer(x)
        reconstructed = self.pca_rebuild(raw_features)

        return self.apply_boundary_constraints(reconstructed, batch_size)


class PCARebuildLayer(Layer):
    def __init__(self, pca_components, pca_mean, original_shape, name="pca_rebuild", **kwargs):
        super().__init__(name=name, **kwargs)
        self.pca_components = tf.constant(pca_components, dtype=tf.float32)
        self.pca_mean = tf.constant(pca_mean, dtype=tf.float32)
        self.original_shape = original_shape

    def call(self, inputs):
        reconstructed = tf.matmul(inputs, self.pca_components) + self.pca_mean
        return tf.reshape(reconstructed, [-1] + list(self.original_shape))

    def get_config(self):
        config = super().get_config()
        config.update({
            'pca_components': self.pca_components.numpy(),
            'pca_mean': self.pca_mean.numpy(),
            'original_shape': self.original_shape
        })
        return config

    @classmethod
    def from_config(cls, config):
        if 'name' not in config:
            config['name'] = "pca_rebuild"
        return cls(**config)


# é…ç½®è·¯å¾„
results_path = r"**"
preprocess_path = os.path.join(results_path, 'preprocess_tools')
model_path = os.path.join(results_path, "final_model")


def load_preprocessing_tools():
    """åŠ è½½æ‰€æœ‰é¢„å¤„ç†å·¥å…·å’Œé…ç½®ä¿¡æ¯ï¼ˆå¢å¼ºéªŒè¯ï¼‰"""
    # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    required_files = [
        'robust_scaler.joblib',
        'feature_selector.joblib',
        'pca_model.joblib',
        'energy_scales.npy',
        'preprocessing_info.joblib'
    ]

    missing_files = []
    for file in required_files:
        if not os.path.exists(os.path.join(preprocess_path, file)):
            missing_files.append(file)

    if missing_files:
        raise FileNotFoundError(f"é¢„å¤„ç†æ–‡ä»¶ç¼ºå¤±: {', '.join(missing_files)}")

    # 2. åŠ è½½å·¥å…·
    scaler = joblib.load(os.path.join(preprocess_path, 'robust_scaler.joblib'))
    selector = joblib.load(os.path.join(preprocess_path, 'feature_selector.joblib'))
    pca_model = joblib.load(os.path.join(preprocess_path, 'pca_model.joblib'))
    energy_scales = np.load(os.path.join(preprocess_path, 'energy_scales.npy'))
    preprocess_info = joblib.load(os.path.join(preprocess_path, 'preprocessing_info.joblib'))

    # 3. éªŒè¯ç‰¹å¾é€‰æ‹©å™¨
    print(f"ç‰¹å¾é€‰æ‹©å™¨è¾“å…¥ç»´åº¦: {selector.n_features_in_}")
    print(f"ç‰¹å¾é€‰æ‹©å™¨è¾“å‡ºç»´åº¦: {selector.n_features_}")

    # ä¸å†å¼ºåˆ¶è¦æ±‚é™ç»´ï¼Œæ”¹ä¸ºè­¦å‘Š
    if selector.n_features_ == selector.n_features_in_:
        print("âš ï¸ è­¦å‘Šï¼šç‰¹å¾é€‰æ‹©å™¨æœªé™ç»´ï¼å°†ä½¿ç”¨åŸå§‹ç‰¹å¾ç»´åº¦")
    elif selector.n_features_ != 3:
        print(f"âš ï¸ è­¦å‘Šï¼šç‰¹å¾é€‰æ‹©å™¨è¾“å‡ºç»´åº¦å¼‚å¸¸ ({selector.n_features_})")

    # 4. è·å–è®­ç»ƒæ—¶ä½¿ç”¨çš„å®é™…ç‰¹å¾ç´¢å¼•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'selected_feature_indices' in preprocess_info:
        print(f"âœ… åŠ è½½è®­ç»ƒæ—¶ç‰¹å¾ç´¢å¼•: {preprocess_info['selected_feature_indices']}")
    else:
        # æ‰‹åŠ¨è®¾ç½®é»˜è®¤ç‰¹å¾ç´¢å¼•ï¼ˆæ ¹æ®è®­ç»ƒæ—¥å¿—è°ƒæ•´ï¼‰
        default_indices = [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14]  # ç¤ºä¾‹ç´¢å¼•
        print(f"âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒç‰¹å¾ç´¢å¼•ï¼Œä½¿ç”¨é»˜è®¤: {default_indices}")
        preprocess_info['selected_feature_indices'] = default_indices

    return scaler, selector, pca_model, energy_scales, preprocess_info


def create_features(params):
    """åˆ›å»ºä¸è®­ç»ƒæ—¶ç›¸åŒçš„ç‰¹å¾"""
    qin = params[0]
    qout = params[1]
    cin = params[2]

    # ç‰¹å¾å·¥ç¨‹
    flow_ratio = qin / (qout + 1e-6)
    conc_ratio = cin / (qin + 1e-6)
    reynolds = (qin * cin) / 1.0
    energy_ratio = (qin ** 2) / (qout + 1e-6)
    momentum_transfer = (qin * qout) / (cin + 1e-6)
    convective_flux = qin * cin
    qin_squared = qin ** 2
    qout_squared = qout ** 2
    cin_squared = cin ** 2
    qin_qout = qin * qout
    qin_cin = qin * cin
    qout_cin = qout * cin

    return np.array([
        qin, qout, cin,
        flow_ratio, conc_ratio, reynolds,
        energy_ratio, momentum_transfer, convective_flux,
        qin_squared, qout_squared, cin_squared,
        qin_qout, qin_cin, qout_cin
    ]).astype(np.float32)


def preprocess_new_data(params, scaler, selector, preprocess_info):
    """é¢„å¤„ç†æ–°è¾“å…¥æ•°æ®ï¼ˆå¢å¼ºé²æ£’æ€§ï¼‰"""
    # 1. åˆ›å»ºç‰¹å¾ï¼ˆ15ç»´ï¼‰
    raw_features = create_features(params)

    # 2. ç‰¹å¾é€‰æ‹©ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„ç‰¹å¾ç´¢å¼•ï¼‰
    selected_indices = preprocess_info.get('selected_feature_indices', list(range(13)))
    selected = raw_features[selected_indices].reshape(1, -1)

    # 3. æ ‡å‡†åŒ–ï¼ˆç¡®ä¿ç»´åº¦åŒ¹é…ï¼‰
    if selected.shape[1] != scaler.n_features_in_:
        print(f"âš ï¸ æ‰‹åŠ¨é™ç»´åç»´åº¦: {selected.shape[1]}, æ ‡å‡†åŒ–å™¨æœŸæœ›: {scaler.n_features_in_}")
        # ç»´åº¦è°ƒæ•´ç­–ç•¥
        if selected.shape[1] > scaler.n_features_in_:
            print(f"ğŸ”„ æˆªå–å‰{scaler.n_features_in_}ä¸ªç‰¹å¾")
            selected = selected[:, :scaler.n_features_in_]
        else:
            print(f"ğŸ”„ å¡«å……é›¶å€¼ä½¿ç»´åº¦åŒ¹é…")
            padding = np.zeros((1, scaler.n_features_in_ - selected.shape[1]))
            selected = np.hstack([selected, padding])

    scaled = scaler.transform(selected)
    return scaled


def predict_new_data(params):
    """é¢„æµ‹æ–°æ•°æ®"""
    # 1. åŠ è½½é¢„å¤„ç†å·¥å…·
    try:
        scaler, selector, pca_model, energy_scales, preprocess_info = load_preprocessing_tools()
    except Exception as e:
        print(f"âŒ é¢„å¤„ç†å·¥å…·åŠ è½½å¤±è´¥: {str(e)}")
        # å°è¯•æ‰‹åŠ¨è®¾ç½®å…³é”®å‚æ•°
        print("ğŸ”„ å°è¯•ä½¿ç”¨é»˜è®¤é¢„å¤„ç†ä¿¡æ¯")
        preprocess_info = {
            'input_dim': 13,  # å…³é”®ä¿®å¤ï¼šä½¿ç”¨13ç»´è¾“å…¥
            'output_dim': 50,
            'n_x': 100, 'n_y': 50,
            'original_shape': (1, 100, 50, 2),
            'selected_feature_indices': list(range(13))  # ä½¿ç”¨13ä¸ªç‰¹å¾
        }
        energy_scales = np.array([1.0])
        # åˆ›å»ºè™šæ‹Ÿæ ‡å‡†åŒ–å™¨å’Œé€‰æ‹©å™¨
        scaler = RobustScaler()
        scaler.fit(np.zeros((1, 13)))  # åŒ¹é…13ç»´è¾“å…¥
        selector = None

        # å°è¯•åŠ è½½PCAæ¨¡å‹
        try:
            pca_model = joblib.load(os.path.join(preprocess_path, 'pca_model.joblib'))
        except:
            print("âŒ PCAæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­é¢„æµ‹")
            return None, None

    # 2. å¢å¼ºæ¨¡å‹åŠ è½½
    try:
        model = load_model(
            model_path,
            custom_objects={
                'PhysicsResBlock': PhysicsResBlock,
                'PhysicsInformedNN': PhysicsInformedNN,
                'PCARebuildLayer': PCARebuildLayer,
                'robust_physics_loss': robust_physics_loss
            },
            compile=False
        )
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼ˆæ ‡å‡†æ–¹å¼ï¼‰")
    except Exception as e:
        print(f"âš ï¸ æ ‡å‡†åŠ è½½å¤±è´¥: {str(e)}")
        print("ğŸ”„ å°è¯•å¤‡ç”¨åŠ è½½æ–¹æ¡ˆ...")

        try:
            # é‡å»ºæ¨¡å‹ç»“æ„ï¼ˆä½¿ç”¨æ­£ç¡®çš„è¾“å…¥ç»´åº¦ï¼‰
            pca_layer = PCARebuildLayer(
                pca_components=pca_model.components_,
                pca_mean=pca_model.mean_,
                original_shape=preprocess_info['original_shape']
            )

            model = PhysicsInformedNN(
                input_dim=preprocess_info['input_dim'],  # ä½¿ç”¨13ç»´è¾“å…¥
                output_dim=preprocess_info['output_dim'],
                n_x=preprocess_info['n_x'],
                n_y=preprocess_info['n_y'],
                pca_layer=pca_layer
            )

            # åŠ è½½æƒé‡
            weights_path = os.path.join(model_path, 'variables', 'variables')
            if os.path.exists(weights_path):
                model.load_weights(weights_path)
                print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
            else:
                # å°è¯•å…¶ä»–å¯èƒ½çš„æƒé‡è·¯å¾„
                print("ğŸ”„ å°è¯•æ›¿ä»£æƒé‡åŠ è½½æ–¹æ¡ˆ")
                model.load_weights(os.path.join(model_path, 'variables'))
        except Exception as e:
            print(f"âŒ æ¨¡å‹é‡å»ºå¤±è´¥: {str(e)}")
            return None, None

    # 3. é¢„å¤„ç†è¾“å…¥æ•°æ®ï¼ˆä¼ é€’preprocess_infoï¼‰
    try:
        input_data = preprocess_new_data(params, scaler, selector, preprocess_info)
        print(f"âœ… é¢„å¤„ç†å®Œæˆï¼Œè¾“å…¥ç»´åº¦: {input_data.shape}")
    except Exception as e:
        print(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {str(e)}")
        return None, None

    # 4. è¿›è¡Œé¢„æµ‹
    try:
        pca_output = model.predict(input_data)
    except Exception as e:
        print(f"âŒ æ¨¡å‹é¢„æµ‹å¤±è´¥: {str(e)}")
        return None, None

    # 5. PCAé€†å˜æ¢é‡å»ºæ¨¡æ€æ•°æ®
    try:
        reconstructed = pca_model.inverse_transform(pca_output)
    except Exception as e:
        print(f"âŒ PCAé€†å˜æ¢å¤±è´¥: {str(e)}")
        return None, None

    # 6. æ¢å¤åŸå§‹å½¢çŠ¶
    try:
        n_samples, n_x, n_y, n_channels = preprocess_info['original_shape']
        reconstructed = reconstructed.reshape(1, n_x, n_y, n_channels)
    except Exception as e:
        print(f"âŒ å½¢çŠ¶æ¢å¤å¤±è´¥: {str(e)}")
        return None, None

    # 7. åˆ†ç¦»å®éƒ¨å’Œè™šéƒ¨
    try:
        real_part = reconstructed[0, :, :, 0]
        imag_part = reconstructed[0, :, :, 1]
    except Exception as e:
        print(f"âŒ å®éƒ¨/è™šéƒ¨åˆ†ç¦»å¤±è´¥: {str(e)}")
        return None, None

    # 8. æ¢å¤èƒ½é‡ç¼©æ”¾
    try:
        avg_energy_scale = np.mean(energy_scales)
        real_part *= avg_energy_scale
        imag_part *= avg_energy_scale
    except Exception as e:
        print(f"âš ï¸ èƒ½é‡ç¼©æ”¾å¤±è´¥: {str(e)}")

    # 9. éªŒè¯è¾“å‡ºå½¢çŠ¶
    try:
        print(f"æ¢å¤å½¢çŠ¶: ({n_x}, {n_y}, {n_channels}) | å®é™…å½¢çŠ¶: {real_part.shape}")
        if real_part.shape != (n_x, n_y):
            print(f"âš ï¸ å®éƒ¨å½¢çŠ¶ä¸åŒ¹é…: æœŸæœ›({n_x}, {n_y}), å®é™…{real_part.shape}")
        if imag_part.shape != (n_x, n_y):
            print(f"âš ï¸ è™šéƒ¨å½¢çŠ¶ä¸åŒ¹é…: æœŸæœ›({n_x}, {n_y}), å®é™…{imag_part.shape}")
    except Exception as e:
        print(f"âš ï¸ å½¢çŠ¶éªŒè¯å¤±è´¥: {str(e)}")

    return real_part, imag_part


def robust_physics_loss(y_true, y_pred, n_x, n_y, epoch, delta=5000.0):
    # åŠ¨æ€è¡°å‡ç‰©ç†çº¦æŸæƒé‡
    decay_factor = max(0.5, 1.0 - epoch / 200)  # çº¿æ€§è¡°å‡
    energy_weight = 0.5 * decay_factor if epoch < 50 else 1.0 * decay_factor
    momentum_weight = 0.1 * decay_factor

    # HuberæŸå¤±
    error = y_true - y_pred
    condition = tf.abs(error) < delta
    squared_loss = 0.5 * tf.square(error)
    linear_loss = delta * (tf.abs(error) - 0.5 * delta)
    base_loss = tf.where(condition, squared_loss, linear_loss)

    # æå–å®éƒ¨
    raw_real = y_pred[..., 0]

    # 1. èƒ½é‡å®ˆæ’çº¦æŸ
    inflow = tf.reduce_sum(raw_real[:, 0, :], axis=1)
    outflow = tf.reduce_sum(raw_real[:, -1, :], axis=1)
    energy_loss = tf.reduce_mean(tf.square(inflow - outflow)) + 1e-6

    # 2. åŠ¨é‡å®ˆæ’çº¦æŸ
    slice1 = tf.strided_slice(
        raw_real,
        [0, 1, 0],
        [tf.shape(raw_real)[0], tf.shape(raw_real)[1], tf.shape(raw_real)[2]],
        [1, 1, 1]
    )
    slice2 = tf.strided_slice(
        raw_real,
        [0, 0, 0],
        [tf.shape(raw_real)[0], tf.shape(raw_real)[1] - 1, tf.shape(raw_real)[2]],
        [1, 1, 1]
    )
    velocity_grad = tf.reduce_mean(tf.abs(slice1 - slice2))
    momentum_loss = 1e-3 * velocity_grad

    # 3. ç®€åŒ–æ­£äº¤çº¦æŸ
    ortho_loss = 0.0
    if epoch >= 20:
        ortho_loss = 1e-4 * tf.reduce_mean(tf.square(raw_real))

    # åŠ¨æ€æƒé‡è°ƒæ•´
    energy_weight = 0.5 if epoch < 30 else 3.0
    momentum_weight = 0.1 if epoch < 30 else 0.8
    ortho_weight = min(0.3, max(0, (epoch - 20) / 20 * 0.3))

    return (tf.reduce_mean(base_loss) +
            energy_weight * energy_loss +
            momentum_weight * momentum_loss +
            ortho_weight * ortho_loss)


if __name__ == "__main__":
    # 1. éªŒè¯é¢„å¤„ç†å·¥å…·
    print("ğŸ§ª éªŒè¯é¢„å¤„ç†å·¥å…·...")
    try:
        scaler, selector, pca_model, energy_scales, preprocess_info = load_preprocessing_tools()
        print("âœ… é¢„å¤„ç†å·¥å…·åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ é¢„å¤„ç†å·¥å…·åŠ è½½å¤±è´¥: {str(e)}")
        # å°è¯•ç»§ç»­è¿è¡Œï¼ˆä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼‰

    # 2. ç‰¹å¾é‡è¦æ€§è¯Šæ–­ï¼ˆä»…åœ¨ç‰¹å¾é€‰æ‹©å™¨å¯ç”¨æ—¶æ‰§è¡Œï¼‰
    if 'selector' in locals() and selector is not None:
        print("\nğŸ” ç‰¹å¾é‡è¦æ€§è¯Šæ–­:")
        try:
            # è·å–ç‰¹å¾é€‰æ‹©å™¨çš„ç‰¹å¾æ’å
            if hasattr(selector, 'ranking_'):
                print("ç‰¹å¾æ’å:", selector.ranking_)
            else:
                print("â„¹ï¸ ç‰¹å¾é€‰æ‹©å™¨æ— ranking_å±æ€§")

            # åˆ›å»ºç‰¹å¾åç§°åˆ—è¡¨
            feature_names = [
                "Qin", "Qout", "Cin",
                "FlowRatio", "ConcRatio", "Reynolds",
                "EnergyRatio", "MomentumTransfer", "ConvectiveFlux",
                "Qin^2", "Qout^2", "Cin^2",
                "Qin*Qout", "Qin*Cin", "Qout*Cin"
            ]

            # æ‰“å°ç‰¹å¾é‡è¦æ€§æ’åº
            if hasattr(selector, 'estimator_') and hasattr(selector.estimator_, 'feature_importances_'):
                print("\nç‰¹å¾é‡è¦æ€§æ’åº:")
                sorted_indices = np.argsort(selector.estimator_.feature_importances_)[::-1]
                for i in sorted_indices:
                    print(f"{feature_names[i]}: {selector.estimator_.feature_importances_[i]:.4f}")
            else:
                print("âŒ æ— æ³•è·å–ç‰¹å¾é‡è¦æ€§ï¼Œé€‰æ‹©å™¨æœªä¿å­˜è¯„ä¼°å™¨")
        except Exception as e:
            print(f"âŒ ç‰¹å¾é‡è¦æ€§è¯Šæ–­å¤±è´¥: {str(e)}")

    # 3. éªŒè¯æ¨¡å‹ç»“æ„é‡å»º
    print("ğŸ§ª éªŒè¯æ¨¡å‹é‡å»ºèƒ½åŠ›...")
    if 'pca_model' in locals() and 'preprocess_info' in locals():
        try:
            pca_layer = PCARebuildLayer(
                pca_components=pca_model.components_,
                pca_mean=pca_model.mean_,
                original_shape=preprocess_info['original_shape']
            )
            test_model = PhysicsInformedNN(
                input_dim=preprocess_info['input_dim'],
                output_dim=preprocess_info['output_dim'],
                n_x=preprocess_info['n_x'],
                n_y=preprocess_info['n_y'],
                pca_layer=pca_layer
            )
            test_model.build(input_shape=(None, preprocess_info['input_dim']))
            print("âœ… æ¨¡å‹ç»“æ„é‡å»ºæˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ¨¡å‹é‡å»ºå¤±è´¥: {str(e)}")
    else:
        print("âš ï¸ è·³è¿‡æ¨¡å‹é‡å»ºï¼Œç¼ºå°‘å¿…è¦ç»„ä»¶")

    # 4. è¿›è¡Œé¢„æµ‹
    new_params = [100, 120, 80]
    print("ğŸš€ å¼€å§‹é¢„æµ‹...")
    try:
        predicted_real, predicted_imag = predict_new_data(new_params)

        if predicted_real is not None and predicted_imag is not None:
            print(f"âœ… é¢„æµ‹æˆåŠŸï¼å®éƒ¨å½¢çŠ¶: {predicted_real.shape}, è™šéƒ¨å½¢çŠ¶: {predicted_imag.shape}")

            # ä¿å­˜ä¸ºnpyæ–‡ä»¶ï¼ˆç¡®ä¿å½¢çŠ¶ä¸€è‡´ï¼‰
            np.save(os.path.join(results_path, 'predicted_real.npy'), predicted_real)
            np.save(os.path.join(results_path, 'predicted_imag.npy'), predicted_imag)
            print(f"ğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜ä¸ºnpyæ–‡ä»¶")

            # å¯è§†åŒ–ç»“æœ
            try:
                import matplotlib.pyplot as plt

                plt.figure(figsize=(12, 5))
                plt.subplot(121)
                plt.imshow(predicted_real, cmap='jet')
                plt.title('Predicted Real Part')
                plt.colorbar()
                plt.subplot(122)
                plt.imshow(predicted_imag, cmap='jet')
                plt.title('Predicted Imaginary Part')
                plt.colorbar()
                plt.tight_layout()
                plt.savefig(os.path.join(results_path, 'prediction_result.png'))
                plt.show()
            except Exception as e:
                print(f"âš ï¸ å¯è§†åŒ–å¤±è´¥: {str(e)}")
        else:
            print("âŒ é¢„æµ‹è¿”å›ç©ºç»“æœ")
    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {str(e)}")
